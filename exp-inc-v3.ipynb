{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:42:00.329884Z",
     "iopub.status.busy": "2024-11-29T17:42:00.329173Z",
     "iopub.status.idle": "2024-11-29T17:42:04.080039Z",
     "shell.execute_reply": "2024-11-29T17:42:04.079323Z",
     "shell.execute_reply.started": "2024-11-29T17:42:00.329837Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:42:04.082125Z",
     "iopub.status.busy": "2024-11-29T17:42:04.081731Z",
     "iopub.status.idle": "2024-11-29T17:42:05.182014Z",
     "shell.execute_reply": "2024-11-29T17:42:05.181326Z",
     "shell.execute_reply.started": "2024-11-29T17:42:04.082098Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import timm\n",
    "# from transformers import ViTModel, ViTFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:42:05.183361Z",
     "iopub.status.busy": "2024-11-29T17:42:05.182937Z",
     "iopub.status.idle": "2024-11-29T17:42:05.882099Z",
     "shell.execute_reply": "2024-11-29T17:42:05.881416Z",
     "shell.execute_reply.started": "2024-11-29T17:42:05.183333Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\", \"lemmatizer\"])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:42:05.883572Z",
     "iopub.status.busy": "2024-11-29T17:42:05.883193Z",
     "iopub.status.idle": "2024-11-29T17:42:05.88865Z",
     "shell.execute_reply": "2024-11-29T17:42:05.887737Z",
     "shell.execute_reply.started": "2024-11-29T17:42:05.883535Z"
    }
   },
   "outputs": [],
   "source": [
    "ENVIRON = \"LOCAL\"\n",
    "CONFIG = {\n",
    "    \"LOCAL\" : {\n",
    "        \"DF_PATH\": \"data/results.csv\",\n",
    "        \"IMAGES_DIR_ROOT\": \"data\",\n",
    "        \"FEATURE_MAPS_PATH\": \"feature_maps\",\n",
    "    },\n",
    "    \"KAGGLE\" : {\n",
    "        \"DF_PATH\": \"/kaggle/input/flickr-image-dataset/flickr30k_images/results.csv\",\n",
    "        \"IMAGES_DIR_ROOT\": \"/kaggle/input/flickr-image-dataset/flickr30k_images\",\n",
    "        \"FEATURE_MAPS_PATH\": \"/kaggle/input/feature-maps\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:49:01.305142Z",
     "iopub.status.busy": "2024-11-29T17:49:01.304317Z",
     "iopub.status.idle": "2024-11-29T17:49:01.309107Z",
     "shell.execute_reply": "2024-11-29T17:49:01.308227Z",
     "shell.execute_reply.started": "2024-11-29T17:49:01.305111Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "# Model\n",
    "N_HEADS = 8\n",
    "N_LAYERS = 6\n",
    "EMBED_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:42:05.901676Z",
     "iopub.status.busy": "2024-11-29T17:42:05.901455Z",
     "iopub.status.idle": "2024-11-29T17:42:06.264136Z",
     "shell.execute_reply": "2024-11-29T17:42:06.263284Z",
     "shell.execute_reply.started": "2024-11-29T17:42:05.901653Z"
    }
   },
   "outputs": [],
   "source": [
    "DF_PATH = CONFIG[ENVIRON][\"DF_PATH\"]\n",
    "df = pd.read_csv(DF_PATH, delimiter=\"|\")\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:42:06.265813Z",
     "iopub.status.busy": "2024-11-29T17:42:06.265464Z",
     "iopub.status.idle": "2024-11-29T17:42:06.379387Z",
     "shell.execute_reply": "2024-11-29T17:42:06.378746Z",
     "shell.execute_reply.started": "2024-11-29T17:42:06.265776Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"comment\"] = df[\" comment\"].apply(lambda x: str(x).strip()) \\\n",
    "                             .apply(lambda x: x.lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:42:06.380951Z",
     "iopub.status.busy": "2024-11-29T17:42:06.38069Z",
     "iopub.status.idle": "2024-11-29T17:45:47.685765Z",
     "shell.execute_reply": "2024-11-29T17:45:47.684807Z",
     "shell.execute_reply.started": "2024-11-29T17:42:06.380926Z"
    }
   },
   "outputs": [],
   "source": [
    "captions_list = df[\"comment\"].to_list()\n",
    "tokens_list = []\n",
    "docs = list(nlp.pipe(captions_list, n_process=-1))\n",
    "# for caption in tqdm(captions_list, desc=\"Vocab Building\"):\n",
    "#     tokens = nlp(caption)\n",
    "#     tokens = list(map(lambda x: x.text, tokens))\n",
    "#     vocab.update(tokens)\n",
    "for doc in tqdm(docs, desc=\"Document Processing\"):\n",
    "    tokens = [token.text for token in doc]\n",
    "    tokens_list.append(tokens)\n",
    "df[\"tokens\"] = tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:47.687602Z",
     "iopub.status.busy": "2024-11-29T17:45:47.687179Z",
     "iopub.status.idle": "2024-11-29T17:45:47.827872Z",
     "shell.execute_reply": "2024-11-29T17:45:47.826935Z",
     "shell.execute_reply.started": "2024-11-29T17:45:47.687559Z"
    }
   },
   "outputs": [],
   "source": [
    "caption_length = df[\"tokens\"].apply(lambda x: len(x))\n",
    "max_len = 15\n",
    "bool_map = (caption_length <= max_len)\n",
    "print(\"No. of rows -\", df[bool_map].shape[0])\n",
    "df = df[bool_map].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:47.829191Z",
     "iopub.status.busy": "2024-11-29T17:45:47.828925Z",
     "iopub.status.idle": "2024-11-29T17:45:47.972271Z",
     "shell.execute_reply": "2024-11-29T17:45:47.97146Z",
     "shell.execute_reply.started": "2024-11-29T17:45:47.829165Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "tokens_list = df[\"tokens\"].to_list()\n",
    "for tokens in tqdm(tokens_list, desc=\"Vocab Building\"):\n",
    "    vocab.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:47.973524Z",
     "iopub.status.busy": "2024-11-29T17:45:47.973249Z",
     "iopub.status.idle": "2024-11-29T17:45:47.987597Z",
     "shell.execute_reply": "2024-11-29T17:45:47.986706Z",
     "shell.execute_reply.started": "2024-11-29T17:45:47.973498Z"
    }
   },
   "outputs": [],
   "source": [
    "START_TOKEN = \"</start>\"\n",
    "END_TOKEN = \"</end>\"\n",
    "PAD_TOKEN = \"</pad>\"\n",
    "\n",
    "vocab.add(START_TOKEN)\n",
    "vocab.add(END_TOKEN)\n",
    "vocab.add(PAD_TOKEN)\n",
    "\n",
    "vocab = sorted(list(vocab)) # Just incase\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(\"Vocab Size -\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:47.98895Z",
     "iopub.status.busy": "2024-11-29T17:45:47.988644Z",
     "iopub.status.idle": "2024-11-29T17:45:48.003646Z",
     "shell.execute_reply": "2024-11-29T17:45:48.002831Z",
     "shell.execute_reply.started": "2024-11-29T17:45:47.988916Z"
    }
   },
   "outputs": [],
   "source": [
    "token_to_idx = {token: i for i, token in enumerate(vocab)}\n",
    "idx_to_token = {v: k for k, v in token_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:48.004768Z",
     "iopub.status.busy": "2024-11-29T17:45:48.004555Z",
     "iopub.status.idle": "2024-11-29T17:45:48.012923Z",
     "shell.execute_reply": "2024-11-29T17:45:48.012174Z",
     "shell.execute_reply.started": "2024-11-29T17:45:48.004747Z"
    }
   },
   "outputs": [],
   "source": [
    "# max_len += 2 # # +2 due to START and END tokens\n",
    "max_len = 17 # +2 due to START and END tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:48.017565Z",
     "iopub.status.busy": "2024-11-29T17:45:48.017224Z",
     "iopub.status.idle": "2024-11-29T17:45:48.734677Z",
     "shell.execute_reply": "2024-11-29T17:45:48.733729Z",
     "shell.execute_reply.started": "2024-11-29T17:45:48.017527Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.drop(columns=[\"comment_number\", \"comment\"], inplace=True)\n",
    "df[\"tokens\"] = df[\"tokens\"].apply(lambda x: [START_TOKEN, ] + x + [END_TOKEN, ])\n",
    "df[\"tokens\"] = df[\"tokens\"].apply(lambda x: x + [PAD_TOKEN, ] * (max_len - len(x)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:48.736518Z",
     "iopub.status.busy": "2024-11-29T17:45:48.736063Z",
     "iopub.status.idle": "2024-11-29T17:45:48.74162Z",
     "shell.execute_reply": "2024-11-29T17:45:48.740488Z",
     "shell.execute_reply.started": "2024-11-29T17:45:48.73647Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = df.sample(frac=.05).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:48.743737Z",
     "iopub.status.busy": "2024-11-29T17:45:48.743075Z",
     "iopub.status.idle": "2024-11-29T17:45:48.823082Z",
     "shell.execute_reply": "2024-11-29T17:45:48.822344Z",
     "shell.execute_reply.started": "2024-11-29T17:45:48.743706Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_test_split(df, test_size):\n",
    "    train_df, val_df = train_test_split(df, test_size=test_size, random_state=42)\n",
    "    \n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "    return train_df, val_df\n",
    "train_df, val_df = get_train_test_split(df, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old Implementation - Ignore (Don't Remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:48.824333Z",
     "iopub.status.busy": "2024-11-29T17:45:48.824092Z",
     "iopub.status.idle": "2024-11-29T17:45:48.829048Z",
     "shell.execute_reply": "2024-11-29T17:45:48.828195Z",
     "shell.execute_reply.started": "2024-11-29T17:45:48.824308Z"
    }
   },
   "outputs": [],
   "source": [
    "# class CaptionsDataset(Dataset):\n",
    "#     def __init__(self, df, token_to_idx, image_transforms):\n",
    "#         self.df = df\n",
    "#         self.token_to_idx = token_to_idx\n",
    "#         self.image_transforms = image_transforms\n",
    "#         resnet = models.resnet18(pretrained=True)\n",
    "#         self.resnet = nn.Sequential(*list(resnet.children())[:-2])\n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "#     def _encode_tokens(self, tokens):\n",
    "#         return [self.token_to_idx[token] for token in tokens]\n",
    "#     def _get_image_features(self, x):\n",
    "#         with torch.no_grad():\n",
    "#             image_features = self.resnet(x.unsqueeze(0))\n",
    "#         return image_features.squeeze()\n",
    "#     def __getitem__(self, i):\n",
    "#         image_name, tokens = self.df.loc[i, \"image_name\"], self.df.loc[i, \"tokens\"]\n",
    "#         target_tokens = tokens[1:] + [PAD_TOKEN, ]\n",
    "#         image_path = os.path.join(\"data\", \"flickr30k_images\", image_name)\n",
    "#         image = Image.open(image_path)\n",
    "#         image = self.image_transforms(image)\n",
    "#         tokens = self._encode_tokens(tokens)\n",
    "#         target_tokens = self._encode_tokens(target_tokens)\n",
    "#         tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "#         target_tokens = torch.tensor(target_tokens, dtype=torch.long)\n",
    "#         image_features = self._get_image_features(image)\n",
    "#         return image_features, tokens, target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:48.830472Z",
     "iopub.status.busy": "2024-11-29T17:45:48.830176Z",
     "iopub.status.idle": "2024-11-29T17:45:48.841585Z",
     "shell.execute_reply": "2024-11-29T17:45:48.840913Z",
     "shell.execute_reply.started": "2024-11-29T17:45:48.830432Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dataset = CaptionsDataset(train_df, token_to_idx, transform)\n",
    "# val_dataset = CaptionsDataset(val_df, token_to_idx, transform)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "# a, b, c = next(iter(train_loader))\n",
    "# a.size(), b.size(), c.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:48.84296Z",
     "iopub.status.busy": "2024-11-29T17:45:48.842678Z",
     "iopub.status.idle": "2024-11-29T17:45:48.851123Z",
     "shell.execute_reply": "2024-11-29T17:45:48.850428Z",
     "shell.execute_reply.started": "2024-11-29T17:45:48.842935Z"
    }
   },
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "transform = transforms.Compose([\n",
    "    \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:48.852314Z",
     "iopub.status.busy": "2024-11-29T17:45:48.852073Z",
     "iopub.status.idle": "2024-11-29T17:45:48.860697Z",
     "shell.execute_reply": "2024-11-29T17:45:48.859984Z",
     "shell.execute_reply.started": "2024-11-29T17:45:48.852289Z"
    }
   },
   "outputs": [],
   "source": [
    "image_encoder_model = timm.create_model('inception_v3', pretrained=True)\n",
    "image_encoder_model = nn.Sequential(*list(image_encoder_model.children())[:-5]).to(device)\n",
    "\n",
    "def get_feature_map(x):\n",
    "    if x.ndimension() == 3:\n",
    "        x = x.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        feature_map = image_encoder_model(x.to(device))\n",
    "    if feature_map.ndimension() == 4:\n",
    "        feature_map = feature_map.squeeze()\n",
    "    feature_map = feature_map.permute(1, 2, 0)\n",
    "    # channels_size = feature_map.size()[-1]\n",
    "    # feature_map = feature_map.view(1, -1, channels_size)\n",
    "    return feature_map\n",
    "\n",
    "    \n",
    "# vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "# vit_feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "    \n",
    "# def get_feature_map(x):\n",
    "#     if x.ndimension() == 3:\n",
    "#         x = x.unsqueeze(0)\n",
    "#     with torch.no_grad():\n",
    "#         inputs = vit_feature_extractor(images=x, return_tensors=\"pt\")\n",
    "#         outputs = vit_model(**inputs)\n",
    "#     features = outputs.last_hidden_state\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:48.861942Z",
     "iopub.status.busy": "2024-11-29T17:45:48.861707Z",
     "iopub.status.idle": "2024-11-29T17:45:48.873828Z",
     "shell.execute_reply": "2024-11-29T17:45:48.873175Z",
     "shell.execute_reply.started": "2024-11-29T17:45:48.861919Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "image_names = set(df[\"image_name\"].to_list())\n",
    "feature_maps = {}\n",
    "for image_name in tqdm(image_names, desc=\"Inception-v3 Feature Maps\"):\n",
    "    image_path = os.path.join(CONFIG[ENVIRON][\"IMAGES_DIR_ROOT\"], \"flickr30k_images\", image_name)\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    feature_map = get_feature_map(image)\n",
    "    feature_maps[image_name] = feature_map\n",
    "# feature_map_path = os.path.join(\"feature_maps\", \"resnet50\")\n",
    "# with open(feature_map_path, \"wb\") as f:\n",
    "#     pickle.dump(feature_maps, f)\n",
    "\n",
    "# import pickle\n",
    "# image_names = set(df[\"image_name\"].to_list())\n",
    "# feature_maps = {}\n",
    "# for image_name in tqdm(image_names, desc=\"ViT Feature Extractor\"):\n",
    "#     image_path = os.path.join(\"data\", \"flickr30k_images\", image_name)\n",
    "#     image = Image.open(image_path)\n",
    "#     image = transform(image)\n",
    "#     feature_map = get_feature_map(image)\n",
    "#     feature_maps[image_name] = feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:48:34.821805Z",
     "iopub.status.busy": "2024-11-29T17:48:34.821461Z",
     "iopub.status.idle": "2024-11-29T17:48:34.829522Z",
     "shell.execute_reply": "2024-11-29T17:48:34.828683Z",
     "shell.execute_reply.started": "2024-11-29T17:48:34.821775Z"
    }
   },
   "outputs": [],
   "source": [
    "class CaptionsDataset(Dataset):\n",
    "    def __init__(self, df, token_to_idx, feature_maps=None):\n",
    "        \n",
    "        self.df = df\n",
    "        self.token_to_idx = token_to_idx\n",
    "        self.feature_maps = feature_maps\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def _encode_tokens(self, tokens):\n",
    "        return [self.token_to_idx[token] for token in tokens]\n",
    "    def _process_image(self, image_name):\n",
    "        image_path = os.path.join(CONFIG[ENVIRON][\"IMAGES_DIR_ROOT\"], \"flickr30k_images\", image_name)\n",
    "        image = Image.open(image_path)\n",
    "        image = transform(image)\n",
    "        image_features = get_feature_map(image)\n",
    "        return image_features\n",
    "    def __getitem__(self, i):\n",
    "        image_name, tokens = self.df.loc[i, \"image_name\"], self.df.loc[i, \"tokens\"]\n",
    "        target_tokens = tokens[1:] + [PAD_TOKEN, ]\n",
    "        tokens = self._encode_tokens(tokens)\n",
    "        target_tokens = self._encode_tokens(target_tokens)\n",
    "        tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "        target_tokens = torch.tensor(target_tokens, dtype=torch.long)\n",
    "        \n",
    "        if self.feature_maps is not None:\n",
    "            image_features = self.feature_maps[image_name]\n",
    "        else:\n",
    "            image_features = self._process_image(image_name)\n",
    "        image_features = image_features.squeeze()\n",
    "        \n",
    "        return image_features, tokens, target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:45:48.886455Z",
     "iopub.status.busy": "2024-11-29T17:45:48.886113Z",
     "iopub.status.idle": "2024-11-29T17:46:14.721266Z",
     "shell.execute_reply": "2024-11-29T17:46:14.720544Z",
     "shell.execute_reply.started": "2024-11-29T17:45:48.886417Z"
    }
   },
   "outputs": [],
   "source": [
    "# FEATURE_MAPS_FILENAME = os.path.join(CONFIG[ENVIRON][\"FEATURE_MAPS_PATH\"], \"resnet18\")\n",
    "# feature_maps = pd.read_pickle(FEATURE_MAPS_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:46:14.727007Z",
     "iopub.status.busy": "2024-11-29T17:46:14.726772Z",
     "iopub.status.idle": "2024-11-29T17:46:14.732306Z",
     "shell.execute_reply": "2024-11-29T17:46:14.731351Z",
     "shell.execute_reply.started": "2024-11-29T17:46:14.726983Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_datasets(df, token_to_idx, feature_maps):\n",
    "    train_df, val_df = get_train_test_split(df, test_size=.2)\n",
    "    train_dataset = CaptionsDataset(train_df, token_to_idx, feature_maps)\n",
    "    val_dataset = CaptionsDataset(val_df, token_to_idx, feature_maps)\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def get_dataloaders(df, token_to_idx, feature_maps, batch_size):\n",
    "    train_dataset, val_dataset = get_datasets(df, token_to_idx, feature_maps)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:46:14.733712Z",
     "iopub.status.busy": "2024-11-29T17:46:14.733463Z",
     "iopub.status.idle": "2024-11-29T17:46:14.747498Z",
     "shell.execute_reply": "2024-11-29T17:46:14.746635Z",
     "shell.execute_reply.started": "2024-11-29T17:46:14.733687Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, embed_dim, p=0.1, max_length=max_len):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.dropout_layer = nn.Dropout(p)\n",
    "        encoding = torch.zeros(max_length, embed_dim)\n",
    "        positions = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
    "        scale_factor = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
    "        encoding[:, 0::2] = torch.sin(positions * scale_factor)\n",
    "        encoding[:, 1::2] = torch.cos(positions * scale_factor)\n",
    "        encoding = encoding.unsqueeze(0)\n",
    "        self.register_buffer('encoding', encoding)\n",
    "    def forward(self, x):\n",
    "        if self.encoding.size(0) < x.size(0):\n",
    "            self.encoding = self.encoding.repeat(x.size(0), 1, 1).to(device)\n",
    "\n",
    "        self.encoding = self.encoding[:x.size(0), :, :]\n",
    "\n",
    "        x = x + self.encoding\n",
    "\n",
    "        return self.dropout_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:46:14.748767Z",
     "iopub.status.busy": "2024-11-29T17:46:14.748534Z",
     "iopub.status.idle": "2024-11-29T17:46:14.759248Z",
     "shell.execute_reply": "2024-11-29T17:46:14.758355Z",
     "shell.execute_reply.started": "2024-11-29T17:46:14.748743Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageCaptioningModel(nn.Module):\n",
    "    def __init__(self, n_heads, n_layers, vocab_size, embed_dim):\n",
    "        super(ImageCaptioningModel, self).__init__()\n",
    "\n",
    "        self.position_encoder = PositionalEmbedding(embed_dim, 0.1)\n",
    "\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=embed_dim, nhead=n_heads)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer=self.decoder_layer, num_layers=n_layers)\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "        self.feature_map_reduce = nn.Linear(1280, EMBED_DIM)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self, param_range=0.1):\n",
    "        self.embedding.weight.data.uniform_(-param_range, param_range)\n",
    "        self.output_layer.bias.data.zero_()\n",
    "        self.output_layer.weight.data.uniform_(-param_range, param_range)\n",
    "\n",
    "    def _create_masks(self, size, decoder_input):\n",
    "        \n",
    "        causal_mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
    "        causal_mask = causal_mask.float().masked_fill(causal_mask == 0, float('-inf')).masked_fill(causal_mask == 1, float(0.0))\n",
    "\n",
    "        pad_mask = decoder_input.float().masked_fill(decoder_input == 0, float(0.0)).masked_fill(decoder_input > 0, float(1.0))\n",
    "        pad_mask_bool = decoder_input == 0\n",
    "\n",
    "        return causal_mask, pad_mask, pad_mask_bool\n",
    "\n",
    "    def forward(self, image_features, decoder_input):\n",
    "\n",
    "        batch_size, *_, channels_size = image_features.size()\n",
    "        image_features = image_features.view(batch_size, 1, -1, channels_size)\n",
    "        image_features = self.feature_map_reduce(image_features)\n",
    "        image_features = image_features.permute(1, 0, 2) # (num_patches, batch_size, embed_dim) or (feature_map_size, batch_size, num_channels)\n",
    "        \n",
    "        decoder_input_embed = self.embedding(decoder_input) * math.sqrt(self.embed_dim)\n",
    "        decoder_input_embed = self.position_encoder(decoder_input_embed)\n",
    "        \n",
    "        decoder_input_embed = decoder_input_embed.permute(1, 0, 2)\n",
    "        causal_mask, pad_mask, pad_mask_bool = self._create_masks(decoder_input.size(1), decoder_input)\n",
    "\n",
    "        causal_mask = causal_mask.to(device)\n",
    "        pad_mask = pad_mask.to(device)\n",
    "        pad_mask_bool = pad_mask_bool.to(device)\n",
    "\n",
    "        decoder_output = self.decoder(tgt=decoder_input_embed, memory=image_features, tgt_mask=causal_mask, tgt_key_padding_mask=pad_mask_bool)\n",
    "        \n",
    "        output = self.output_layer(decoder_output)\n",
    "        return output, pad_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:46:14.760555Z",
     "iopub.status.busy": "2024-11-29T17:46:14.760305Z",
     "iopub.status.idle": "2024-11-29T17:46:14.773681Z",
     "shell.execute_reply": "2024-11-29T17:46:14.772898Z",
     "shell.execute_reply.started": "2024-11-29T17:46:14.760532Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    for image_features, tokens, target_tokens in progress_bar:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        image_features = image_features.to(device)\n",
    "        tokens = tokens.to(device)\n",
    "        target_tokens = target_tokens.to(device)\n",
    "        \n",
    "        logits, padding_mask = model(image_features, tokens)\n",
    "        logits = logits.permute(1, 2, 0)\n",
    "\n",
    "        loss = criterion(logits, target_tokens)\n",
    "        loss_masked = torch.mul(loss, padding_mask)\n",
    "\n",
    "        batch_loss = torch.sum(loss_masked) / torch.sum(padding_mask)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += batch_loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(batch_loss=batch_loss.item(), refresh=True)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:46:14.774962Z",
     "iopub.status.busy": "2024-11-29T17:46:14.774716Z",
     "iopub.status.idle": "2024-11-29T17:46:14.788882Z",
     "shell.execute_reply": "2024-11-29T17:46:14.788179Z",
     "shell.execute_reply.started": "2024-11-29T17:46:14.774938Z"
    }
   },
   "outputs": [],
   "source": [
    "def val_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(val_loader, desc=\"Validation\")\n",
    "    with torch.inference_mode():\n",
    "        for image_features, tokens, target_tokens in progress_bar:\n",
    "            \n",
    "            image_features = image_features.to(device)\n",
    "            tokens = tokens.to(device)\n",
    "            target_tokens = target_tokens.to(device)\n",
    "\n",
    "            logits, padding_mask = model(image_features, tokens)\n",
    "            logits = logits.permute(1, 2, 0)\n",
    "\n",
    "            loss = criterion(logits, target_tokens)\n",
    "            loss_masked = torch.mul(loss, padding_mask)\n",
    "\n",
    "            batch_loss = torch.sum(loss_masked) / torch.sum(padding_mask)\n",
    "\n",
    "            total_loss += batch_loss.item()\n",
    "\n",
    "            progress_bar.set_postfix(batch_loss=batch_loss.item(), refresh=True)\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:46:14.789942Z",
     "iopub.status.busy": "2024-11-29T17:46:14.789718Z",
     "iopub.status.idle": "2024-11-29T17:46:14.797928Z",
     "shell.execute_reply": "2024-11-29T17:46:14.797154Z",
     "shell.execute_reply.started": "2024-11-29T17:46:14.789919Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch : [{epoch + 1}/{num_epochs}]\")\n",
    "\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = val_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(f\"Current Learning Rate: {param_group['lr']}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model, \"best_model\")\n",
    "            print(\"Model saved!\")\n",
    "\n",
    "    print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:55:07.88088Z",
     "iopub.status.busy": "2024-11-29T17:55:07.880087Z",
     "iopub.status.idle": "2024-11-29T17:55:08.26714Z",
     "shell.execute_reply": "2024-11-29T17:55:08.266459Z",
     "shell.execute_reply.started": "2024-11-29T17:55:07.880844Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = ImageCaptioningModel(N_HEADS, N_LAYERS, vocab_size, EMBED_DIM).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=.3, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:54:51.414028Z",
     "iopub.status.busy": "2024-11-29T17:54:51.413211Z",
     "iopub.status.idle": "2024-11-29T17:54:51.500956Z",
     "shell.execute_reply": "2024-11-29T17:54:51.499951Z",
     "shell.execute_reply.started": "2024-11-29T17:54:51.413994Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_dataloaders(df, token_to_idx, feature_maps, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T17:55:10.195448Z",
     "iopub.status.busy": "2024-11-29T17:55:10.194858Z",
     "iopub.status.idle": "2024-11-29T17:55:16.405035Z",
     "shell.execute_reply": "2024-11-29T17:55:16.403848Z",
     "shell.execute_reply.started": "2024-11-29T17:55:10.195378Z"
    }
   },
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, EPOCHS, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-29T17:46:17.796898Z",
     "iopub.status.idle": "2024-11-29T17:46:17.797219Z",
     "shell.execute_reply": "2024-11-29T17:46:17.797077Z",
     "shell.execute_reply.started": "2024-11-29T17:46:17.797061Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_caption(K, image_name):\n",
    "    \n",
    "    image_path = os.path.join(CONFIG[ENVIRON][\"IMAGES_DIR_ROOT\"], \"flickr30k_images\", image_name)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    plt.imshow(image)\n",
    "\n",
    "    model.eval()\n",
    "    feature_map = feature_maps[image_name].to(device)\n",
    "\n",
    "\n",
    "    input_tokens = [token_to_idx[PAD_TOKEN]] * max_len\n",
    "    input_tokens[0] = token_to_idx[START_TOKEN]\n",
    "\n",
    "    input_tokens = torch.tensor(input_tokens).unsqueeze(0).to(device)\n",
    "    predicted_sentence = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for eval_iter in range(0, max_len-1):\n",
    "\n",
    "            logits, padding_mask = model.forward(feature_map, input_tokens)\n",
    "\n",
    "            logits = logits[eval_iter, 0, :]\n",
    "\n",
    "            values = torch.topk(logits, K).values.tolist()\n",
    "            indices = torch.topk(logits, K).indices.tolist()\n",
    "\n",
    "            next_word_index = random.choices(indices, values, k = 1)[0]\n",
    "\n",
    "            next_word = idx_to_token[next_word_index]\n",
    "\n",
    "            input_tokens[:, eval_iter+1] = next_word_index\n",
    "\n",
    "\n",
    "            if next_word == '</end>' :\n",
    "                break\n",
    "\n",
    "            predicted_sentence.append(next_word)\n",
    "    print(\"\\n\")\n",
    "    print(\"Predicted caption : \")\n",
    "    print(\" \".join(predicted_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-29T17:46:17.798675Z",
     "iopub.status.idle": "2024-11-29T17:46:17.798939Z",
     "shell.execute_reply": "2024-11-29T17:46:17.798822Z",
     "shell.execute_reply.started": "2024-11-29T17:46:17.798809Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"best_model\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-29T17:46:17.79983Z",
     "iopub.status.idle": "2024-11-29T17:46:17.800114Z",
     "shell.execute_reply": "2024-11-29T17:46:17.799992Z",
     "shell.execute_reply.started": "2024-11-29T17:46:17.799977Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-29T17:46:17.800948Z",
     "iopub.status.idle": "2024-11-29T17:46:17.801214Z",
     "shell.execute_reply": "2024-11-29T17:46:17.801097Z",
     "shell.execute_reply.started": "2024-11-29T17:46:17.801084Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-29T17:46:17.802224Z",
     "iopub.status.idle": "2024-11-29T17:46:17.802554Z",
     "shell.execute_reply": "2024-11-29T17:46:17.802387Z",
     "shell.execute_reply.started": "2024-11-29T17:46:17.802372Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-29T17:46:17.803962Z",
     "iopub.status.idle": "2024-11-29T17:46:17.804263Z",
     "shell.execute_reply": "2024-11-29T17:46:17.804126Z",
     "shell.execute_reply.started": "2024-11-29T17:46:17.804111Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-29T17:46:17.805143Z",
     "iopub.status.idle": "2024-11-29T17:46:17.805463Z",
     "shell.execute_reply": "2024-11-29T17:46:17.80531Z",
     "shell.execute_reply.started": "2024-11-29T17:46:17.805295Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-29T17:46:17.807253Z",
     "iopub.status.idle": "2024-11-29T17:46:17.807568Z",
     "shell.execute_reply": "2024-11-29T17:46:17.807431Z",
     "shell.execute_reply.started": "2024-11-29T17:46:17.807387Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-29T17:46:17.808968Z",
     "iopub.status.idle": "2024-11-29T17:46:17.809233Z",
     "shell.execute_reply": "2024-11-29T17:46:17.809116Z",
     "shell.execute_reply.started": "2024-11-29T17:46:17.809103Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-29T17:46:17.810672Z",
     "iopub.status.idle": "2024-11-29T17:46:17.810964Z",
     "shell.execute_reply": "2024-11-29T17:46:17.810838Z",
     "shell.execute_reply.started": "2024-11-29T17:46:17.810823Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 31296,
     "sourceId": 39911,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
