{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:20:00.839360Z",
     "iopub.status.busy": "2024-12-02T00:20:00.838678Z",
     "iopub.status.idle": "2024-12-02T00:20:07.272547Z",
     "shell.execute_reply": "2024-12-02T00:20:07.271848Z",
     "shell.execute_reply.started": "2024-12-02T00:20:00.839326Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:24:58.962086Z",
     "iopub.status.busy": "2024-12-02T00:24:58.961683Z",
     "iopub.status.idle": "2024-12-02T00:24:58.967190Z",
     "shell.execute_reply": "2024-12-02T00:24:58.965945Z",
     "shell.execute_reply.started": "2024-12-02T00:24:58.962050Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# from torchvision import models, transforms\n",
    "# import timm\n",
    "from transformers import ViTModel, ViTFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:20:09.564086Z",
     "iopub.status.busy": "2024-12-02T00:20:09.563695Z",
     "iopub.status.idle": "2024-12-02T00:20:10.268917Z",
     "shell.execute_reply": "2024-12-02T00:20:10.268007Z",
     "shell.execute_reply.started": "2024-12-02T00:20:09.564044Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\", \"lemmatizer\"])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:20:10.270251Z",
     "iopub.status.busy": "2024-12-02T00:20:10.269985Z",
     "iopub.status.idle": "2024-12-02T00:20:10.274595Z",
     "shell.execute_reply": "2024-12-02T00:20:10.273715Z",
     "shell.execute_reply.started": "2024-12-02T00:20:10.270227Z"
    }
   },
   "outputs": [],
   "source": [
    "ENVIRON = \"LOCAL\"\n",
    "CONFIG = {\n",
    "    \"LOCAL\" : {\n",
    "        \"DF_PATH\": \"data/results.csv\",\n",
    "        \"IMAGES_DIR_ROOT\": \"data\",\n",
    "        \"FEATURE_MAPS_PATH\": \"feature_maps\",\n",
    "    },\n",
    "    \"KAGGLE\" : {\n",
    "        \"DF_PATH\": \"/kaggle/input/flickr-image-dataset/flickr30k_images/results.csv\",\n",
    "        \"IMAGES_DIR_ROOT\": \"/kaggle/input/flickr-image-dataset/flickr30k_images\",\n",
    "        \"FEATURE_MAPS_PATH\": \"/kaggle/input/feature-maps\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:20:10.276766Z",
     "iopub.status.busy": "2024-12-02T00:20:10.276528Z",
     "iopub.status.idle": "2024-12-02T00:20:10.287329Z",
     "shell.execute_reply": "2024-12-02T00:20:10.286502Z",
     "shell.execute_reply.started": "2024-12-02T00:20:10.276743Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "# Model\n",
    "N_HEADS = 8\n",
    "N_LAYERS = 6\n",
    "EMBED_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:20:10.288918Z",
     "iopub.status.busy": "2024-12-02T00:20:10.288377Z",
     "iopub.status.idle": "2024-12-02T00:20:10.725344Z",
     "shell.execute_reply": "2024-12-02T00:20:10.724488Z",
     "shell.execute_reply.started": "2024-12-02T00:20:10.288882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Two young guys with shaggy hair look at their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Two young , White males are outside near many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name  comment_number  \\\n",
       "0  1000092795.jpg               0   \n",
       "1  1000092795.jpg               1   \n",
       "2  1000092795.jpg               2   \n",
       "3  1000092795.jpg               3   \n",
       "4  1000092795.jpg               4   \n",
       "\n",
       "                                             comment  \n",
       "0   Two young guys with shaggy hair look at their...  \n",
       "1   Two young , White males are outside near many...  \n",
       "2   Two men in green shirts are standing in a yard .  \n",
       "3       A man in a blue shirt standing in a garden .  \n",
       "4            Two friends enjoy time spent together .  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_PATH = CONFIG[ENVIRON][\"DF_PATH\"]\n",
    "df = pd.read_csv(DF_PATH, delimiter=\"|\")\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:20:10.726976Z",
     "iopub.status.busy": "2024-12-02T00:20:10.726693Z",
     "iopub.status.idle": "2024-12-02T00:20:10.838791Z",
     "shell.execute_reply": "2024-12-02T00:20:10.837826Z",
     "shell.execute_reply.started": "2024-12-02T00:20:10.726928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Two young guys with shaggy hair look at their...</td>\n",
       "      <td>two young guys with shaggy hair look at their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Two young , White males are outside near many...</td>\n",
       "      <td>two young , white males are outside near many ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "      <td>two men in green shirts are standing in a yard .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "      <td>a man in a blue shirt standing in a garden .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "      <td>two friends enjoy time spent together .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name  comment_number  \\\n",
       "0  1000092795.jpg               0   \n",
       "1  1000092795.jpg               1   \n",
       "2  1000092795.jpg               2   \n",
       "3  1000092795.jpg               3   \n",
       "4  1000092795.jpg               4   \n",
       "\n",
       "                                             comment  \\\n",
       "0   Two young guys with shaggy hair look at their...   \n",
       "1   Two young , White males are outside near many...   \n",
       "2   Two men in green shirts are standing in a yard .   \n",
       "3       A man in a blue shirt standing in a garden .   \n",
       "4            Two friends enjoy time spent together .   \n",
       "\n",
       "                                             comment  \n",
       "0  two young guys with shaggy hair look at their ...  \n",
       "1  two young , white males are outside near many ...  \n",
       "2   two men in green shirts are standing in a yard .  \n",
       "3       a man in a blue shirt standing in a garden .  \n",
       "4            two friends enjoy time spent together .  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"comment\"] = df[\" comment\"].apply(lambda x: str(x).strip()) \\\n",
    "                             .apply(lambda x: x.lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:20:10.840394Z",
     "iopub.status.busy": "2024-12-02T00:20:10.840030Z",
     "iopub.status.idle": "2024-12-02T00:23:50.955038Z",
     "shell.execute_reply": "2024-12-02T00:23:50.954074Z",
     "shell.execute_reply.started": "2024-12-02T00:20:10.840357Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Document Processing: 100%|██████████| 158914/158914 [00:01<00:00, 149750.87it/s]\n"
     ]
    }
   ],
   "source": [
    "captions_list = df[\"comment\"].to_list()\n",
    "tokens_list = []\n",
    "docs = list(nlp.pipe(captions_list, n_process=-1))\n",
    "# for caption in tqdm(captions_list, desc=\"Vocab Building\"):\n",
    "#     tokens = nlp(caption)\n",
    "#     tokens = list(map(lambda x: x.text, tokens))\n",
    "#     vocab.update(tokens)\n",
    "for doc in tqdm(docs, desc=\"Document Processing\"):\n",
    "    tokens = [token.text for token in doc]\n",
    "    tokens_list.append(tokens)\n",
    "df[\"tokens\"] = tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:23:50.957125Z",
     "iopub.status.busy": "2024-12-02T00:23:50.956432Z",
     "iopub.status.idle": "2024-12-02T00:23:51.091079Z",
     "shell.execute_reply": "2024-12-02T00:23:51.090124Z",
     "shell.execute_reply.started": "2024-12-02T00:23:50.957080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows - 115038\n"
     ]
    }
   ],
   "source": [
    "caption_length = df[\"tokens\"].apply(lambda x: len(x))\n",
    "max_len = 15\n",
    "bool_map = (caption_length <= max_len)\n",
    "print(\"No. of rows -\", df[bool_map].shape[0])\n",
    "df = df[bool_map].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:23:51.092397Z",
     "iopub.status.busy": "2024-12-02T00:23:51.092134Z",
     "iopub.status.idle": "2024-12-02T00:23:51.238191Z",
     "shell.execute_reply": "2024-12-02T00:23:51.237360Z",
     "shell.execute_reply.started": "2024-12-02T00:23:51.092371Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vocab Building: 100%|██████████| 115038/115038 [00:00<00:00, 999735.50it/s] \n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "tokens_list = df[\"tokens\"].to_list()\n",
    "for tokens in tqdm(tokens_list, desc=\"Vocab Building\"):\n",
    "    vocab.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:23:51.240089Z",
     "iopub.status.busy": "2024-12-02T00:23:51.239438Z",
     "iopub.status.idle": "2024-12-02T00:23:51.254198Z",
     "shell.execute_reply": "2024-12-02T00:23:51.253409Z",
     "shell.execute_reply.started": "2024-12-02T00:23:51.240049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size - 14945\n"
     ]
    }
   ],
   "source": [
    "START_TOKEN = \"</start>\"\n",
    "END_TOKEN = \"</end>\"\n",
    "PAD_TOKEN = \"</pad>\"\n",
    "\n",
    "vocab.add(START_TOKEN)\n",
    "vocab.add(END_TOKEN)\n",
    "vocab.add(PAD_TOKEN)\n",
    "\n",
    "vocab = sorted(list(vocab)) # Just incase\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(\"Vocab Size -\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:23:51.256238Z",
     "iopub.status.busy": "2024-12-02T00:23:51.255463Z",
     "iopub.status.idle": "2024-12-02T00:23:51.266288Z",
     "shell.execute_reply": "2024-12-02T00:23:51.265473Z",
     "shell.execute_reply.started": "2024-12-02T00:23:51.256201Z"
    }
   },
   "outputs": [],
   "source": [
    "token_to_idx = {token: i for i, token in enumerate(vocab)}\n",
    "idx_to_token = {v: k for k, v in token_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:23:51.267359Z",
     "iopub.status.busy": "2024-12-02T00:23:51.267128Z",
     "iopub.status.idle": "2024-12-02T00:23:51.275490Z",
     "shell.execute_reply": "2024-12-02T00:23:51.274766Z",
     "shell.execute_reply.started": "2024-12-02T00:23:51.267336Z"
    }
   },
   "outputs": [],
   "source": [
    "# max_len += 2 # # +2 due to START and END tokens\n",
    "max_len = 17 # +2 due to START and END tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:23:51.279308Z",
     "iopub.status.busy": "2024-12-02T00:23:51.279044Z",
     "iopub.status.idle": "2024-12-02T00:23:51.975485Z",
     "shell.execute_reply": "2024-12-02T00:23:51.974605Z",
     "shell.execute_reply.started": "2024-12-02T00:23:51.279284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Two young , White males are outside near many...</td>\n",
       "      <td>two young , white males are outside near many ...</td>\n",
       "      <td>[&lt;/start&gt;, two, young, ,, white, males, are, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "      <td>two men in green shirts are standing in a yard .</td>\n",
       "      <td>[&lt;/start&gt;, two, men, in, green, shirts, are, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "      <td>a man in a blue shirt standing in a garden .</td>\n",
       "      <td>[&lt;/start&gt;, a, man, in, a, blue, shirt, standin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "      <td>two friends enjoy time spent together .</td>\n",
       "      <td>[&lt;/start&gt;, two, friends, enjoy, time, spent, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Several men in hard hats are operating a gian...</td>\n",
       "      <td>several men in hard hats are operating a giant...</td>\n",
       "      <td>[&lt;/start&gt;, several, men, in, hard, hats, are, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name  comment_number  \\\n",
       "0  1000092795.jpg               1   \n",
       "1  1000092795.jpg               2   \n",
       "2  1000092795.jpg               3   \n",
       "3  1000092795.jpg               4   \n",
       "4    10002456.jpg               0   \n",
       "\n",
       "                                             comment  \\\n",
       "0   Two young , White males are outside near many...   \n",
       "1   Two men in green shirts are standing in a yard .   \n",
       "2       A man in a blue shirt standing in a garden .   \n",
       "3            Two friends enjoy time spent together .   \n",
       "4   Several men in hard hats are operating a gian...   \n",
       "\n",
       "                                             comment  \\\n",
       "0  two young , white males are outside near many ...   \n",
       "1   two men in green shirts are standing in a yard .   \n",
       "2       a man in a blue shirt standing in a garden .   \n",
       "3            two friends enjoy time spent together .   \n",
       "4  several men in hard hats are operating a giant...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [</start>, two, young, ,, white, males, are, o...  \n",
       "1  [</start>, two, men, in, green, shirts, are, s...  \n",
       "2  [</start>, a, man, in, a, blue, shirt, standin...  \n",
       "3  [</start>, two, friends, enjoy, time, spent, t...  \n",
       "4  [</start>, several, men, in, hard, hats, are, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.drop(columns=[\"comment_number\", \"comment\"], inplace=True)\n",
    "df[\"tokens\"] = df[\"tokens\"].apply(lambda x: [START_TOKEN, ] + x + [END_TOKEN, ])\n",
    "df[\"tokens\"] = df[\"tokens\"].apply(lambda x: x + [PAD_TOKEN, ] * (max_len - len(x)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:23:51.976890Z",
     "iopub.status.busy": "2024-12-02T00:23:51.976584Z",
     "iopub.status.idle": "2024-12-02T00:23:51.980568Z",
     "shell.execute_reply": "2024-12-02T00:23:51.979737Z",
     "shell.execute_reply.started": "2024-12-02T00:23:51.976862Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = df.sample(frac=.05).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:23:51.982055Z",
     "iopub.status.busy": "2024-12-02T00:23:51.981712Z",
     "iopub.status.idle": "2024-12-02T00:23:52.058213Z",
     "shell.execute_reply": "2024-12-02T00:23:52.057179Z",
     "shell.execute_reply.started": "2024-12-02T00:23:51.982020Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_test_split(df, test_size):\n",
    "    train_df, val_df = train_test_split(df, test_size=test_size, random_state=42)\n",
    "    \n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "    return train_df, val_df\n",
    "train_df, val_df = get_train_test_split(df, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old Implementation - Ignore (Don't Remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:23:52.059803Z",
     "iopub.status.busy": "2024-12-02T00:23:52.059533Z",
     "iopub.status.idle": "2024-12-02T00:23:52.064011Z",
     "shell.execute_reply": "2024-12-02T00:23:52.063159Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.059768Z"
    }
   },
   "outputs": [],
   "source": [
    "# class CaptionsDataset(Dataset):\n",
    "#     def __init__(self, df, token_to_idx, image_transforms):\n",
    "#         self.df = df\n",
    "#         self.token_to_idx = token_to_idx\n",
    "#         self.image_transforms = image_transforms\n",
    "#         resnet = models.resnet18(pretrained=True)\n",
    "#         self.resnet = nn.Sequential(*list(resnet.children())[:-2])\n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "#     def _encode_tokens(self, tokens):\n",
    "#         return [self.token_to_idx[token] for token in tokens]\n",
    "#     def _get_image_features(self, x):\n",
    "#         with torch.no_grad():\n",
    "#             image_features = self.resnet(x.unsqueeze(0))\n",
    "#         return image_features.squeeze()\n",
    "#     def __getitem__(self, i):\n",
    "#         image_name, tokens = self.df.loc[i, \"image_name\"], self.df.loc[i, \"tokens\"]\n",
    "#         target_tokens = tokens[1:] + [PAD_TOKEN, ]\n",
    "#         image_path = os.path.join(\"data\", \"flickr30k_images\", image_name)\n",
    "#         image = Image.open(image_path)\n",
    "#         image = self.image_transforms(image)\n",
    "#         tokens = self._encode_tokens(tokens)\n",
    "#         target_tokens = self._encode_tokens(target_tokens)\n",
    "#         tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "#         target_tokens = torch.tensor(target_tokens, dtype=torch.long)\n",
    "#         image_features = self._get_image_features(image)\n",
    "#         return image_features, tokens, target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:23:52.065454Z",
     "iopub.status.busy": "2024-12-02T00:23:52.065160Z",
     "iopub.status.idle": "2024-12-02T00:23:52.078479Z",
     "shell.execute_reply": "2024-12-02T00:23:52.077700Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.065424Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dataset = CaptionsDataset(train_df, token_to_idx, transform)\n",
    "# val_dataset = CaptionsDataset(val_df, token_to_idx, transform)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "# a, b, c = next(iter(train_loader))\n",
    "# a.size(), b.size(), c.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:23:52.080049Z",
     "iopub.status.busy": "2024-12-02T00:23:52.079517Z",
     "iopub.status.idle": "2024-12-02T00:23:52.089154Z",
     "shell.execute_reply": "2024-12-02T00:23:52.088380Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.080022Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean = [0.485, 0.456, 0.406]\n",
    "# std = [0.229, 0.224, 0.225]\n",
    "# transform = transforms.Compose([\n",
    "    \n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=mean, std=std),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:25:09.977519Z",
     "iopub.status.busy": "2024-12-02T00:25:09.977192Z",
     "iopub.status.idle": "2024-12-02T00:25:13.661835Z",
     "shell.execute_reply": "2024-12-02T00:25:13.660824Z",
     "shell.execute_reply.started": "2024-12-02T00:25:09.977490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8433ece62e254bfd87af8381b2e4b977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image_encoder_model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "# image_encoder_model = nn.Sequential(*list(image_encoder_model.children())[:-1]).to(device)\n",
    "\n",
    "# def get_feature_map(x):\n",
    "#     if x.ndimension() == 3:\n",
    "#         x = x.unsqueeze(0)\n",
    "#     with torch.no_grad():\n",
    "#         feature_map = image_encoder_model(x.to(device))\n",
    "#     if feature_map.ndimension() == 4:\n",
    "#         feature_map = feature_map.squeeze()\n",
    "#     # feature_map = feature_map.permute(1, 2, 0)\n",
    "#     # channels_size = feature_map.size()[-1]\n",
    "#     # feature_map = feature_map.view(1, -1, channels_size)\n",
    "#     return feature_map\n",
    "\n",
    "    \n",
    "vit_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "vit_feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "    \n",
    "def get_feature_map(x):\n",
    "    if x.ndimension() == 3:\n",
    "        x = x.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        inputs = vit_feature_extractor(images=x, return_tensors=\"pt\")\n",
    "        outputs = vit_model(**inputs)\n",
    "    features = outputs.last_hidden_state\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T00:25:16.213740Z",
     "iopub.status.busy": "2024-12-02T00:25:16.213036Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Swin Transformer Feature Maps:   1%|▏         | 469/31551 [00:17<18:19, 28.28it/s]"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "# image_names = set(df[\"image_name\"].to_list())\n",
    "# feature_maps = {}\n",
    "# for image_name in tqdm(image_names, desc=\"Swin Transformer Feature Maps\"):\n",
    "#     image_path = os.path.join(CONFIG[ENVIRON][\"IMAGES_DIR_ROOT\"], \"flickr30k_images\", image_name)\n",
    "#     image = Image.open(image_path)\n",
    "#     image = transform(image)\n",
    "#     feature_map = get_feature_map(image)\n",
    "#     feature_maps[image_name] = feature_map\n",
    "# feature_map_path = os.path.join(\"feature_maps\", \"resnet50\")\n",
    "# with open(feature_map_path, \"wb\") as f:\n",
    "#     pickle.dump(feature_maps, f)\n",
    "\n",
    "import pickle\n",
    "image_names = set(df[\"image_name\"].to_list())\n",
    "feature_maps = {}\n",
    "for image_name in tqdm(image_names, desc=\"ViT Feature Extractor\"):\n",
    "    image_path = os.path.join(\"data\", \"flickr30k_images\", image_name)\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    feature_map = get_feature_map(image)\n",
    "    feature_map = feature_map[:, 0, :].unsqueeze(1)\n",
    "    feature_maps[image_name] = feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.366799Z",
     "iopub.status.idle": "2024-12-02T00:23:52.367249Z",
     "shell.execute_reply": "2024-12-02T00:23:52.367047Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.367023Z"
    }
   },
   "outputs": [],
   "source": [
    "class CaptionsDataset(Dataset):\n",
    "    def __init__(self, df, token_to_idx, feature_maps=None):\n",
    "        \n",
    "        self.df = df\n",
    "        self.token_to_idx = token_to_idx\n",
    "        self.feature_maps = feature_maps\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def _encode_tokens(self, tokens):\n",
    "        return [self.token_to_idx[token] for token in tokens]\n",
    "    def _process_image(self, image_name):\n",
    "        image_path = os.path.join(CONFIG[ENVIRON][\"IMAGES_DIR_ROOT\"], \"flickr30k_images\", image_name)\n",
    "        image = Image.open(image_path)\n",
    "        image = transform(image)\n",
    "        image_features = get_feature_map(image)\n",
    "        return image_features\n",
    "    def __getitem__(self, i):\n",
    "        image_name, tokens = self.df.loc[i, \"image_name\"], self.df.loc[i, \"tokens\"]\n",
    "        target_tokens = tokens[1:] + [PAD_TOKEN, ]\n",
    "        tokens = self._encode_tokens(tokens)\n",
    "        target_tokens = self._encode_tokens(target_tokens)\n",
    "        tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "        target_tokens = torch.tensor(target_tokens, dtype=torch.long)\n",
    "        \n",
    "        if self.feature_maps is not None:\n",
    "            image_features = self.feature_maps[image_name]\n",
    "        else:\n",
    "            image_features = self._process_image(image_name)\n",
    "        image_features = image_features.squeeze()\n",
    "        \n",
    "        return image_features, tokens, target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.368803Z",
     "iopub.status.idle": "2024-12-02T00:23:52.369261Z",
     "shell.execute_reply": "2024-12-02T00:23:52.369062Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.369039Z"
    }
   },
   "outputs": [],
   "source": [
    "# FEATURE_MAPS_FILENAME = os.path.join(CONFIG[ENVIRON][\"FEATURE_MAPS_PATH\"], \"vit\")\n",
    "# feature_maps = pd.read_pickle(FEATURE_MAPS_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.371101Z",
     "iopub.status.idle": "2024-12-02T00:23:52.371530Z",
     "shell.execute_reply": "2024-12-02T00:23:52.371331Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.371308Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_datasets(df, token_to_idx, feature_maps):\n",
    "    train_df, val_df = get_train_test_split(df, test_size=.2)\n",
    "    train_dataset = CaptionsDataset(train_df, token_to_idx, feature_maps)\n",
    "    val_dataset = CaptionsDataset(val_df, token_to_idx, feature_maps)\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def get_dataloaders(df, token_to_idx, feature_maps, batch_size):\n",
    "    train_dataset, val_dataset = get_datasets(df, token_to_idx, feature_maps)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.372774Z",
     "iopub.status.idle": "2024-12-02T00:23:52.373218Z",
     "shell.execute_reply": "2024-12-02T00:23:52.373021Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.372999Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, embed_dim, p=0.1, max_length=max_len):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.dropout_layer = nn.Dropout(p)\n",
    "        encoding = torch.zeros(max_length, embed_dim)\n",
    "        positions = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
    "        scale_factor = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
    "        encoding[:, 0::2] = torch.sin(positions * scale_factor)\n",
    "        encoding[:, 1::2] = torch.cos(positions * scale_factor)\n",
    "        encoding = encoding.unsqueeze(0)\n",
    "        self.register_buffer('encoding', encoding)\n",
    "    def forward(self, x):\n",
    "        if self.encoding.size(0) < x.size(0):\n",
    "            self.encoding = self.encoding.repeat(x.size(0), 1, 1).to(device)\n",
    "\n",
    "        self.encoding = self.encoding[:x.size(0), :, :]\n",
    "\n",
    "        x = x + self.encoding\n",
    "\n",
    "        return self.dropout_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.374740Z",
     "iopub.status.idle": "2024-12-02T00:23:52.375194Z",
     "shell.execute_reply": "2024-12-02T00:23:52.374986Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.374964Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageCaptioningModel(nn.Module):\n",
    "    def __init__(self, n_heads, n_layers, vocab_size, embed_dim):\n",
    "        super(ImageCaptioningModel, self).__init__()\n",
    "\n",
    "        self.position_encoder = PositionalEmbedding(embed_dim, 0.1)\n",
    "\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=embed_dim, nhead=n_heads)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer=self.decoder_layer, num_layers=n_layers)\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "        self.feature_map_reduce = nn.Linear(1024, EMBED_DIM)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self, param_range=0.1):\n",
    "        self.embedding.weight.data.uniform_(-param_range, param_range)\n",
    "        self.output_layer.bias.data.zero_()\n",
    "        self.output_layer.weight.data.uniform_(-param_range, param_range)\n",
    "\n",
    "    def _create_masks(self, size, decoder_input):\n",
    "        \n",
    "        causal_mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
    "        causal_mask = causal_mask.float().masked_fill(causal_mask == 0, float('-inf')).masked_fill(causal_mask == 1, float(0.0))\n",
    "\n",
    "        pad_mask = decoder_input.float().masked_fill(decoder_input == 0, float(0.0)).masked_fill(decoder_input > 0, float(1.0))\n",
    "        pad_mask_bool = decoder_input == 0\n",
    "\n",
    "        return causal_mask, pad_mask, pad_mask_bool\n",
    "\n",
    "    def forward(self, image_features, decoder_input):\n",
    "\n",
    "        image_features = image_features.permute(1, 0, 2) # (num_patches, batch_size, embed_dim) or (feature_map_size, batch_size, num_channels)\n",
    "        \n",
    "        decoder_input_embed = self.embedding(decoder_input) * math.sqrt(self.embed_dim)\n",
    "        decoder_input_embed = self.position_encoder(decoder_input_embed)\n",
    "        \n",
    "        decoder_input_embed = decoder_input_embed.permute(1, 0, 2)\n",
    "        causal_mask, pad_mask, pad_mask_bool = self._create_masks(decoder_input.size(1), decoder_input)\n",
    "\n",
    "        causal_mask = causal_mask.to(device)\n",
    "        pad_mask = pad_mask.to(device)\n",
    "        pad_mask_bool = pad_mask_bool.to(device)\n",
    "\n",
    "        decoder_output = self.decoder(tgt=decoder_input_embed, memory=image_features, tgt_mask=causal_mask, tgt_key_padding_mask=pad_mask_bool)\n",
    "        \n",
    "        output = self.output_layer(decoder_output)\n",
    "        return output, pad_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.377018Z",
     "iopub.status.idle": "2024-12-02T00:23:52.377297Z",
     "shell.execute_reply": "2024-12-02T00:23:52.377177Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.377163Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    for image_features, tokens, target_tokens in progress_bar:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        image_features = image_features.to(device)\n",
    "        tokens = tokens.to(device)\n",
    "        target_tokens = target_tokens.to(device)\n",
    "        \n",
    "        logits, padding_mask = model(image_features, tokens)\n",
    "        logits = logits.permute(1, 2, 0)\n",
    "\n",
    "        loss = criterion(logits, target_tokens)\n",
    "        loss_masked = torch.mul(loss, padding_mask)\n",
    "\n",
    "        batch_loss = torch.sum(loss_masked) / torch.sum(padding_mask)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += batch_loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(batch_loss=batch_loss.item(), refresh=True)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.378307Z",
     "iopub.status.idle": "2024-12-02T00:23:52.378606Z",
     "shell.execute_reply": "2024-12-02T00:23:52.378475Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.378460Z"
    }
   },
   "outputs": [],
   "source": [
    "def val_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(val_loader, desc=\"Validation\")\n",
    "    with torch.inference_mode():\n",
    "        for image_features, tokens, target_tokens in progress_bar:\n",
    "            \n",
    "            image_features = image_features.to(device)\n",
    "            tokens = tokens.to(device)\n",
    "            target_tokens = target_tokens.to(device)\n",
    "\n",
    "            logits, padding_mask = model(image_features, tokens)\n",
    "            logits = logits.permute(1, 2, 0)\n",
    "\n",
    "            loss = criterion(logits, target_tokens)\n",
    "            loss_masked = torch.mul(loss, padding_mask)\n",
    "\n",
    "            batch_loss = torch.sum(loss_masked) / torch.sum(padding_mask)\n",
    "\n",
    "            total_loss += batch_loss.item()\n",
    "\n",
    "            progress_bar.set_postfix(batch_loss=batch_loss.item(), refresh=True)\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.380137Z",
     "iopub.status.idle": "2024-12-02T00:23:52.380556Z",
     "shell.execute_reply": "2024-12-02T00:23:52.380363Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.380341Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch : [{epoch + 1}/{num_epochs}]\")\n",
    "\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = val_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(f\"Current Learning Rate: {param_group['lr']}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model, \"best_model\")\n",
    "            print(\"Model saved!\")\n",
    "\n",
    "    print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.381590Z",
     "iopub.status.idle": "2024-12-02T00:23:52.381856Z",
     "shell.execute_reply": "2024-12-02T00:23:52.381737Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.381723Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = ImageCaptioningModel(N_HEADS, N_LAYERS, vocab_size, EMBED_DIM).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=.3, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.383476Z",
     "iopub.status.idle": "2024-12-02T00:23:52.383771Z",
     "shell.execute_reply": "2024-12-02T00:23:52.383646Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.383631Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_dataloaders(df, token_to_idx, feature_maps, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.384669Z",
     "iopub.status.idle": "2024-12-02T00:23:52.384938Z",
     "shell.execute_reply": "2024-12-02T00:23:52.384815Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.384802Z"
    }
   },
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, EPOCHS, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.386540Z",
     "iopub.status.idle": "2024-12-02T00:23:52.386970Z",
     "shell.execute_reply": "2024-12-02T00:23:52.386758Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.386737Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_caption(K, image_name):\n",
    "    \n",
    "    image_path = os.path.join(CONFIG[ENVIRON][\"IMAGES_DIR_ROOT\"], \"flickr30k_images\", image_name)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    plt.imshow(image)\n",
    "\n",
    "    model.eval()\n",
    "    feature_map = feature_maps[image_name].to(device)\n",
    "\n",
    "\n",
    "    input_tokens = [token_to_idx[PAD_TOKEN]] * max_len\n",
    "    input_tokens[0] = token_to_idx[START_TOKEN]\n",
    "\n",
    "    input_tokens = torch.tensor(input_tokens).unsqueeze(0).to(device)\n",
    "    predicted_sentence = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for eval_iter in range(0, max_len-1):\n",
    "\n",
    "            logits, padding_mask = model.forward(feature_map, input_tokens)\n",
    "\n",
    "            logits = logits[eval_iter, 0, :]\n",
    "\n",
    "            values = torch.topk(logits, K).values.tolist()\n",
    "            indices = torch.topk(logits, K).indices.tolist()\n",
    "\n",
    "            next_word_index = random.choices(indices, values, k = 1)[0]\n",
    "\n",
    "            next_word = idx_to_token[next_word_index]\n",
    "\n",
    "            input_tokens[:, eval_iter+1] = next_word_index\n",
    "\n",
    "\n",
    "            if next_word == '</end>' :\n",
    "                break\n",
    "\n",
    "            predicted_sentence.append(next_word)\n",
    "    print(\"\\n\")\n",
    "    print(\"Predicted caption : \")\n",
    "    print(\" \".join(predicted_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.388369Z",
     "iopub.status.idle": "2024-12-02T00:23:52.388789Z",
     "shell.execute_reply": "2024-12-02T00:23:52.388594Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.388570Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"best_model\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.390018Z",
     "iopub.status.idle": "2024-12-02T00:23:52.390436Z",
     "shell.execute_reply": "2024-12-02T00:23:52.390243Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.390222Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.391828Z",
     "iopub.status.idle": "2024-12-02T00:23:52.392274Z",
     "shell.execute_reply": "2024-12-02T00:23:52.392066Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.392044Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.393309Z",
     "iopub.status.idle": "2024-12-02T00:23:52.393808Z",
     "shell.execute_reply": "2024-12-02T00:23:52.393581Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.393554Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.395697Z",
     "iopub.status.idle": "2024-12-02T00:23:52.396005Z",
     "shell.execute_reply": "2024-12-02T00:23:52.395852Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.395837Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.396971Z",
     "iopub.status.idle": "2024-12-02T00:23:52.397276Z",
     "shell.execute_reply": "2024-12-02T00:23:52.397152Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.397137Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.398208Z",
     "iopub.status.idle": "2024-12-02T00:23:52.398498Z",
     "shell.execute_reply": "2024-12-02T00:23:52.398373Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.398358Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.400099Z",
     "iopub.status.idle": "2024-12-02T00:23:52.400394Z",
     "shell.execute_reply": "2024-12-02T00:23:52.400268Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.400254Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-02T00:23:52.401395Z",
     "iopub.status.idle": "2024-12-02T00:23:52.401657Z",
     "shell.execute_reply": "2024-12-02T00:23:52.401541Z",
     "shell.execute_reply.started": "2024-12-02T00:23:52.401528Z"
    }
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "generate_caption(K=1, image_name=val_df.loc[i, \"image_name\"])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 31296,
     "sourceId": 39911,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6189052,
     "sourceId": 10046013,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
